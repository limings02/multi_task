experiment:
  name: "deepfm_sharedbottom_cvr_ctr"

data:
  processed_dir: "data/processed"
  metadata_path: "data/processed/metadata.json"
  batch_size: 256
  num_workers: 0
  pin_memory: false
  persistent_workers: false
  drop_last: false
  debug: false
  seed: 20260127
  neg_keep_prob_train: 0.4  # keep 50% 负样本，正样本全保留

embedding:
  default_embedding_dim: 8
  embedding_dim_overrides: {}
  mode: "sum" # 其实是mean，只是因为iterdataset不允许，后面转为手动实现了

model:
  name: "deepfm_shared_bottom_ctr_cvr"
  backbone:
    use_legacy_pseudo_deepfm: false
    return_logit_parts: true
    per_head_add:
      ctr: { use_wide: true, use_fm: true }
      cvr: { use_wide: true, use_fm: true }
      ctcvr: { use_wide: true, use_fm: true }
  enabled_heads: ["ctr","cvr"]
  tasks: ["ctr", "cvr"]
  heads:
    default:
      mlp_dims: [128]
      dropout: 0.1
      use_bn: false
      activation: "relu"
    ctr: {}
    cvr: {}
  deep_hidden_dims: [256, 128]
  deep_dropout: 0.2
  deep_activation: "relu"
  deep_use_bn: false
  fm_enabled: true
  fm_projection_dim: 16
  out_dim: 128

optim:
  lr: 0.001
  weight_decay: 1e-6
  betas: [0.9, 0.999]
  eps: 1.0e-8

loss:
  w_ctr: 1.0
  w_cvr: 1.0
  eps: 1.0e-6

runtime:
  device: "cuda"
  epochs: 1
  # debug_logit_every: 1          # 每步打印一次 logit 分解统计
  # debug_linear_stats: true      # 打印 per-field wide 输出与 bag_len/权重分布
  # debug_fm_stats: true          # 打印 FM 输出分布
  # debug_dataloader_assert: true
  log_every: 4000
  amp: true
  grad_diag_enabled: true
  max_train_steps: 20000 # smoke
  max_valid_steps: 4000  # smoke
  grad_clip_norm: 1.0
  seed: 20260127
  resume_path: null
  auto_eval: true
  auto_eval_split: "valid"
  auto_eval_save_preds: true
  auto_eval_ckpt: "best"  # "best" or "last"
  save_last: false

